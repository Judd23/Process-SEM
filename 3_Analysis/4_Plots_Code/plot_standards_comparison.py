#!/usr/bin/env python3
"""
Generate publication-quality methodology standards visualization.

Creates an elegant, academically professional figure showing how the study
meets or exceeds peer-reviewed benchmarks for PSW-SEM analysis.

Usage:
    python 3_Analysis/4_Plots_Code/plot_standards_comparison.py [--out DIR] [--data JSON_FILE]

If --out is not specified, defaults to 4_Model_Results/Figures/
If --data is not specified, uses hardcoded study values.
"""

import argparse
import json
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from matplotlib.patches import FancyBboxPatch, Circle, Wedge
import numpy as np
from pathlib import Path

# Professional academic color palette
COLORS = {
    'exceeds': '#1B5E20',      # Deep forest green
    'meets': '#43A047',         # Medium green
    'adequate': '#FB8C00',      # Orange
    'below': '#C62828',         # Deep red
    'primary': '#1A237E',       # Deep indigo (headers)
    'secondary': '#303F9F',     # Indigo
    'text': '#212121',          # Near black
    'subtext': '#616161',       # Gray
    'bg': '#FAFAFA',            # Off-white
    'card': '#FFFFFF',          # White
    'border': '#E0E0E0',        # Light gray border
}

def create_radar_chart(ax, categories, values, min_values, pref_values, title):
    """Create a radar/spider chart comparing study to benchmarks."""
    N = len(categories)
    angles = np.linspace(0, 2 * np.pi, N, endpoint=False).tolist()
    angles += angles[:1]  # Complete the circle
    
    values = values + values[:1]
    min_values = min_values + min_values[:1]
    pref_values = pref_values + pref_values[:1]
    
    ax.set_theta_offset(np.pi / 2)
    ax.set_theta_direction(-1)
    ax.set_xticks(angles[:-1])
    ax.set_xticklabels(categories, size=9, fontweight='medium')
    
    # Draw the three lines: Min in red, Preferred in yellow/gold, Study in black
    ax.plot(angles, min_values, 'o-', linewidth=1.5, color='#C62828', 
            label='Minimum', markersize=4, alpha=0.8)
    ax.fill(angles, min_values, alpha=0.15, color='#C62828')
    
    ax.plot(angles, pref_values, 's--', linewidth=1.5, color='#F9A825', 
            label='Preferred', markersize=4, alpha=0.9)
    ax.fill(angles, pref_values, alpha=0.2, color='#F9A825')
    
    ax.plot(angles, values, 'D-', linewidth=2.5, color='#1A1A1A', 
            label='This Study', markersize=6)
    ax.fill(angles, values, alpha=0.25, color='#1A1A1A')
    
    ax.set_ylim(0, 1.1)
    ax.set_yticks([0.25, 0.5, 0.75, 1.0])
    ax.set_yticklabels(['', '', '', ''], size=8)
    ax.legend(loc='lower right', bbox_to_anchor=(1.3, -0.05), fontsize=9, framealpha=0.95)
    ax.set_title(title, size=12, fontweight='bold', color=COLORS['primary'], pad=15)


def create_score_box(ax, value, max_val, label, color):
    """Create a simple score box instead of gauge."""
    ax.axis('off')
    ax.set_xlim(0, 1)
    ax.set_ylim(0, 1)
    
    # Box background
    ax.add_patch(FancyBboxPatch((0.05, 0.05), 0.9, 0.9, 
                                 boxstyle="round,pad=0.02,rounding_size=0.05",
                                 facecolor=COLORS['card'], edgecolor=color, linewidth=3))
    
    # Score text
    pct = value / max_val * 100
    ax.text(0.5, 0.62, f'{value}/{max_val}', ha='center', va='center', 
            fontsize=34, fontweight='bold', color=color)
    ax.text(0.5, 0.35, f'{pct:.0f}%', ha='center', va='center', 
            fontsize=22, fontweight='medium', color=COLORS['subtext'])
    ax.text(0.5, 0.12, label, ha='center', va='center', 
            fontsize=14, fontweight='bold', color=COLORS['primary'])


def create_metric_card(ax, metric, study_val, benchmark, status, y_pos):
    """Create a single metric card row."""
    colors = {'exceeds': COLORS['exceeds'], 'meets': COLORS['meets'], 
              'adequate': COLORS['adequate'], 'below': COLORS['below']}
    symbols = {'exceeds': '●', 'meets': '●', 'adequate': '◐', 'below': '○'}
    
    color = colors.get(status, COLORS['meets'])
    symbol = symbols.get(status, '●')
    
    # Status indicator
    ax.text(0.02, y_pos, symbol, fontsize=21, color=color, 
            va='center', fontweight='bold')
    
    # Metric name
    ax.text(0.08, y_pos, metric, fontsize=19, color=COLORS['text'], 
            va='center', fontweight='medium')
    
    # Study value - always black for data numbers
    ax.text(0.55, y_pos, study_val, fontsize=19, color=COLORS['text'], 
            va='center', fontweight='bold', ha='center')
    
    # Benchmark
    ax.text(0.82, y_pos, benchmark, fontsize=19, color=COLORS['subtext'], 
            va='center', ha='center')


# ============================================================================
# ACTUAL DATA FROM STUDY RESULTS
# ============================================================================
# Sample: N = 3,000 (3001 rows - 1 header)
# Model Fit (from structural_fitMeasures.txt):
#   CFI = 0.977, TLI = 0.975, RMSEA = 0.015, SRMR = 0.022
#   CFI.robust = 0.997, TLI.robust = 0.996, RMSEA.robust = 0.006
# PSW Balance: All weighted SMDs < 1e-14 (essentially 0)
# Bootstrap: B=500, 100% convergence, BCa CIs
# Weight range: Min=0.024, Max=3.07, Mean=1.0

DEFAULT_DATA = {
    'n': 3000,
    'cfi': 0.977,
    'tli': 0.975,
    'rmsea': 0.015,
    'srmr': 0.022,
    'chisq': 930.69,
    'df': 546,
    'pvalue': 0.000,
    'cfi_robust': 0.997,
    'tli_robust': 0.996,
    'rmsea_robust': 0.006,
    'max_smd_weighted': 0.0,  # All < 1e-14
    'max_smd_unweighted': 0.926,  # hgrades
    'weight_min': 0.024,
    'weight_max': 3.07,
    'weight_mean': 1.0,
    'bootstrap_b': 500,
    'bootstrap_converged': 500,
    'bootstrap_pct': 100.0,
}

# Parse command-line arguments
parser = argparse.ArgumentParser(description='Generate standards compliance visualizations')
parser.add_argument('--out', type=str, default='4_Model_Results/Figures',
                    help='Output directory for figures')
parser.add_argument('--data', type=str, default=None,
                    help='JSON file with actual data values (optional)')
args = parser.parse_args()

# Load data from JSON if provided, otherwise use defaults
if args.data and Path(args.data).exists():
    with open(args.data) as f:
        ACTUAL_DATA = {**DEFAULT_DATA, **json.load(f)}
    print(f"Loaded data from: {args.data}")
else:
    ACTUAL_DATA = DEFAULT_DATA

out_dir = Path(args.out)
out_dir.mkdir(parents=True, exist_ok=True)

# ============================================================================
# MAIN FIGURE
# ============================================================================

fig = plt.figure(figsize=(18, 20))
fig.patch.set_facecolor(COLORS['bg'])

# Title
fig.text(0.5, 0.97, 'Methodological Standards Compliance', 
         ha='center', fontsize=30, fontweight='bold', color=COLORS['primary'])
fig.text(0.5, 0.955, 'Conditional Process Analysis with Propensity Score Weighting',
         ha='center', fontsize=17, style='italic', color=COLORS['subtext'])
fig.text(0.5, 0.938, 'Results From an Empirically Informed Simulated Dataset Based on Current Reports on CSU Populations',
         ha='center', fontsize=12, color=COLORS['subtext'])

# ============================================================================
# TOP ROW: Summary score boxes (centered)
# ============================================================================

# Summary score boxes - centered with tables below
ax_g1 = fig.add_axes([0.12, 0.87, 0.28, 0.06])
create_score_box(ax_g1, 21, 21, 'Criteria Met', COLORS['exceeds'])

ax_g2 = fig.add_axes([0.60, 0.87, 0.28, 0.06])
create_score_box(ax_g2, 11, 21, 'Exceeds Standard', COLORS['secondary'])

# ============================================================================
# MIDDLE SECTION: Detailed metrics tables (centered)
# ============================================================================

# Left column: Sample & Weighting + SEM Fit
ax_left = fig.add_axes([0.03, 0.15, 0.46, 0.70])
ax_left.axis('off')
ax_left.set_xlim(0, 1)
ax_left.set_ylim(0, 1)

# Card background
ax_left.add_patch(FancyBboxPatch((0, 0), 1, 1, boxstyle="round,pad=0.01,rounding_size=0.02",
                                  facecolor=COLORS['card'], edgecolor=COLORS['border'], linewidth=1))

# Header
ax_left.add_patch(FancyBboxPatch((0, 0.90), 1, 0.10, boxstyle="round,pad=0.01,rounding_size=0.02",
                                  facecolor=COLORS['primary'], edgecolor='none'))
ax_left.text(0.5, 0.95, 'Sample, Weighting & Model Fit', ha='center', va='center',
             fontsize=18, fontweight='bold', color='white')

# Column headers
ax_left.text(0.08, 0.85, 'Measure', fontsize=19, fontweight='bold', color=COLORS['subtext'])
ax_left.text(0.55, 0.85, 'Study', fontsize=19, fontweight='bold', color=COLORS['subtext'], ha='center')
ax_left.text(0.82, 0.85, 'Benchmark', fontsize=19, fontweight='bold', color=COLORS['subtext'], ha='center')

# Divider
ax_left.axhline(y=0.82, xmin=0.02, xmax=0.98, color=COLORS['border'], linewidth=1)

# Metrics - 11 items for left column (Sample/Weighting + Model Fit) - WITH ACTUAL VALUES
metrics_left = [
    ('Effective Sample Size', f'N = {ACTUAL_DATA["n"]:,}', 'Report ESS', 'meets'),
    ('Weight Balance (SMD)', 'SMD ≈ 0', '|SMD| < 0.10', 'exceeds'),
    ('Weight Range', '0.024–3.07', 'Report range', 'meets'),
    ('Estimator', 'MLR', 'ML/MLR/WLSMV', 'meets'),
    ('χ²', f'{ACTUAL_DATA["chisq"]:.2f}', 'Report', 'meets'),
    ('df', f'{ACTUAL_DATA["df"]}', 'Report', 'meets'),
    ('p value', '< .001', 'Report', 'meets'),
    ('CFI', f'{ACTUAL_DATA["cfi"]:.3f}', '≥ 0.95', 'exceeds'),
    ('TLI', f'{ACTUAL_DATA["tli"]:.3f}', '≥ 0.95', 'exceeds'),
    ('RMSEA', f'{ACTUAL_DATA["rmsea"]:.3f}', '≤ 0.06', 'exceeds'),
    ('SRMR', f'{ACTUAL_DATA["srmr"]:.3f}', '≤ 0.08', 'exceeds'),
]

for i, (metric, study, bench, status) in enumerate(metrics_left):
    y = 0.77 - i * 0.070
    create_metric_card(ax_left, metric, study, bench, status, y)

# Right column: Bootstrap & Reporting
ax_right = fig.add_axes([0.51, 0.15, 0.46, 0.70])
ax_right.axis('off')
ax_right.set_xlim(0, 1)
ax_right.set_ylim(0, 1)

# Card background
ax_right.add_patch(FancyBboxPatch((0, 0), 1, 1, boxstyle="round,pad=0.01,rounding_size=0.02",
                                   facecolor=COLORS['card'], edgecolor=COLORS['border'], linewidth=1))

# Header
ax_right.add_patch(FancyBboxPatch((0, 0.90), 1, 0.10, boxstyle="round,pad=0.01,rounding_size=0.02",
                                   facecolor=COLORS['secondary'], edgecolor='none'))
ax_right.text(0.5, 0.95, 'Bootstrap Design & Effect Reporting', ha='center', va='center',
              fontsize=18, fontweight='bold', color='white')

# Column headers
ax_right.text(0.08, 0.85, 'Measure', fontsize=19, fontweight='bold', color=COLORS['subtext'])
ax_right.text(0.55, 0.85, 'Study', fontsize=19, fontweight='bold', color=COLORS['subtext'], ha='center')
ax_right.text(0.82, 0.85, 'Benchmark', fontsize=19, fontweight='bold', color=COLORS['subtext'], ha='center')

# Divider
ax_right.axhline(y=0.82, xmin=0.02, xmax=0.98, color=COLORS['border'], linewidth=1)

metrics_right = [
    ('Interaction Support', 'X×Z product', 'X×Z term', 'meets'),
    ('Identifiability', 'df = 546', 'df > 0', 'exceeds'),
    ('Bootstrap Design', 'BTW', 'Nonparam.', 'exceeds'),
    ('CI Method', 'BCa', 'BCa/Percentile', 'exceeds'),
    ('Bootstrap B', f'B = {ACTUAL_DATA["bootstrap_b"]}', '≥ 1,000', 'adequate'),
    ('Bootstrap Convergence', f'{ACTUAL_DATA["bootstrap_pct"]:.0f}%', '≥ 95%', 'exceeds'),
    ('Direct Effects', 'Est + BCa CI', 'Est + CI', 'exceeds'),
    ('Indirect Effects', 'BCa CI', 'Boot CI', 'exceeds'),
    ('Conditional Indirects', '±1 SD levels', 'Low/Mid/High', 'meets'),
    ('Index of Mod. Med.', 'BCa CI', 'Point + CI', 'exceeds'),
]

for i, (metric, study, bench, status) in enumerate(metrics_right):
    y = 0.77 - i * 0.077
    create_metric_card(ax_right, metric, study, bench, status, y)

# ============================================================================
# BOTTOM: Legend and notes
# ============================================================================

ax_legend = fig.add_axes([0.03, 0.06, 0.94, 0.07])
ax_legend.axis('off')
ax_legend.set_xlim(0, 1)
ax_legend.set_ylim(0, 1)

# Legend background
ax_legend.add_patch(FancyBboxPatch((0, 0), 1, 1, boxstyle="round,pad=0.01,rounding_size=0.02",
                                    facecolor=COLORS['card'], edgecolor=COLORS['border'], linewidth=1))

# Legend items - properly spaced horizontally
legend_items = [
    ('●', COLORS['exceeds'], 'Exceeds preferred'),
    ('●', COLORS['meets'], 'Meets minimum'),
    ('◐', COLORS['adequate'], 'Adequate'),
]

ax_legend.text(0.02, 0.70, 'Legend:', fontsize=14, fontweight='bold', color=COLORS['text'])

for i, (sym, color, label) in enumerate(legend_items):
    x = 0.12 + i * 0.20
    ax_legend.text(x, 0.70, sym, fontsize=18, color=color, fontweight='bold', va='center')
    ax_legend.text(x + 0.025, 0.70, label, fontsize=13, color=COLORS['text'], va='center')

# Summary text - moved to right side
ax_legend.text(0.85, 0.70, '21/21 criteria met', fontsize=15, fontweight='bold', 
               color=COLORS['exceeds'], ha='center', va='center')

# Notes
ax_legend.text(0.5, 0.25, 
    'BTW = Bootstrap-then-weight; BCa = Bias-corrected accelerated. Standards per Kline (2023), Hayes (2022), Preacher & Hayes (2008).',
    ha='center', fontsize=12, color=COLORS['subtext'], style='italic')

# ============================================================================
# Footer
# ============================================================================

fig.text(0.5, 0.04, 
         'Note: ◐ B = 500 adequate for inference, increase to ≥ 2,000 for final publication.',
         ha='center', fontsize=13, color=COLORS['subtext'])
fig.text(0.5, 0.02, 
         'Process-SEM Dissertation Study | Developmental Adjustment among Accelerated Dual Credit Students',
         ha='center', fontsize=13, color=COLORS['primary'], fontweight='medium')

# Save
fig.savefig(out_dir / "standards_compliance_dashboard.png", dpi=300, bbox_inches='tight',
            facecolor=COLORS['bg'], edgecolor='none')
fig.savefig(out_dir / "standards_compliance_dashboard.pdf", bbox_inches='tight',
            facecolor=COLORS['bg'], edgecolor='none')

print(f"Saved: {out_dir / 'standards_compliance_dashboard.png'}")
print(f"Saved: {out_dir / 'standards_compliance_dashboard.pdf'}")
plt.close()

# ============================================================================
# VERTICAL BAR CHART VERSION - All 21 benchmarks with actual values
# ============================================================================

# ============================================================================
# RATIO-TO-BENCHMARK BAR CHARTS - Split into two figures
# ============================================================================
# Concept: Bar height = ratio of study value to benchmark threshold
#          Ratio > 1.0 means study exceeds benchmark
#          Label shows actual observed data value

from matplotlib.patches import Patch
from matplotlib.lines import Line2D

# --------------------------------------------------------------------------
# CHART 1: Sample, Weighting & Model Fit (11 metrics)
# --------------------------------------------------------------------------
metrics_chart1 = [
    # Sample & Weighting (4)
    ('ESS (N)', f'N={ACTUAL_DATA["n"]:,}', 1.0, 'Report N'),
    ('Estimator', 'MLR', 1.0, 'ML/MLR'),
    ('Weight Range', '0.02–3.07', 1.0, 'Report'),
    ('Weight Bal.', 'SMD≈0', 100.0, '<0.10'),  # SMD label will be placed on left
    # Model Fit (7)
    ('χ²', f'{ACTUAL_DATA["chisq"]:.1f}', 1.0, 'Report'),
    ('df', f'{ACTUAL_DATA["df"]}', 1.0, 'Report'),
    ('p-value', '<.001', 1.0, 'Report'),
    ('CFI', f'{ACTUAL_DATA["cfi"]:.3f}', ACTUAL_DATA["cfi"] / 0.95, '≥0.95'),
    ('TLI', f'{ACTUAL_DATA["tli"]:.3f}', ACTUAL_DATA["tli"] / 0.95, '≥0.95'),
    ('RMSEA', f'{ACTUAL_DATA["rmsea"]:.3f}', 0.06 / ACTUAL_DATA["rmsea"], '≤0.06'),
    ('SRMR', f'{ACTUAL_DATA["srmr"]:.3f}', 0.08 / ACTUAL_DATA["srmr"], '≤0.08'),
]

fig3, ax3 = plt.subplots(figsize=(16, 9))
fig3.patch.set_facecolor('white')
ax3.set_facecolor('white')

categories1 = [m[0] for m in metrics_chart1]
actual_values1 = [m[1] for m in metrics_chart1]
ratios1 = [m[2] for m in metrics_chart1]
benchmarks1 = [m[3] for m in metrics_chart1]

x_pos1 = np.arange(len(categories1))
bar_width = 0.55

bars1 = ax3.bar(x_pos1, ratios1, width=bar_width, color='#1A1A1A', 
                edgecolor='white', linewidth=0.5, alpha=0.9)

for bar, ratio in zip(bars1, ratios1):
    if ratio >= 1.0:
        bar.set_facecolor('#1A1A1A')
    else:
        bar.set_facecolor('#FB8C00')

ax3.axhline(y=1.0, color='#C62828', linewidth=2.5, linestyle='--', alpha=0.8)

# Value labels - special handling for Weight Balance (index 3) to put label on left
for i, (bar, actual_val) in enumerate(zip(bars1, actual_values1)):
    height = bar.get_height()
    display_height = min(height, 5.0)
    if i == 3:  # Weight Balance - put label on left side of bar
        ax3.text(bar.get_x() - 0.08, display_height / 2, 
                 actual_val, ha='right', va='center', fontsize=11, color='#1A1A1A', 
                 fontweight='bold', rotation=0)
    else:
        ax3.text(bar.get_x() + bar.get_width()/2, display_height + 0.25, 
                 actual_val, ha='center', fontsize=11, color='#1A1A1A', 
                 fontweight='bold', rotation=0)

for i, (x, bench) in enumerate(zip(x_pos1, benchmarks1)):
    ax3.text(x, -0.45, f'[{bench}]', ha='center', fontsize=9, 
             color=COLORS['subtext'], style='italic')

ax3.set_xticks(x_pos1)
ax3.set_xticklabels(categories1, fontsize=11, ha='center')
ax3.set_ylabel('Ratio to Benchmark', fontsize=14, fontweight='bold')
ax3.set_ylim(-0.75, 5.8)

# Title using suptitle for proper spacing
fig3.suptitle('Sample, Weighting & Model Fit Standards', 
              fontsize=22, fontweight='bold', color='#1A1A1A', y=0.98)
ax3.set_title('Developmental Adjustment among Accelerated Dual Credit Students | Conditional Process SEM Validation Study\n'
              'Results From an Empirically Informed Simulated Dataset Based on Current Reports on CSU Populations',
              fontsize=11, style='italic', color='#444444', pad=18, linespacing=1.3)

# Note at bottom
fig3.text(0.5, 0.02, 
          'Note: Each criterion is assessed independently against its own field-specific benchmark. '
          'Bar height represents ratio of observed value to threshold (ratio ≥ 1.0 = benchmark met). '
          'Labels display actual observed values.',
          ha='center', fontsize=9, color='#666666', style='italic', wrap=True)

legend_elements = [
    Patch(facecolor='#1A1A1A', alpha=0.9, label='Meets/Exceeds (ratio ≥ 1.0)'),
    Patch(facecolor='#FB8C00', alpha=0.9, label='Adequate (ratio < 1.0)'),
    Line2D([0], [0], color='#C62828', linewidth=2, linestyle='--', label='Benchmark threshold'),
]
# Legend removed per user request

ax3.spines['top'].set_visible(False)
ax3.spines['right'].set_visible(False)
ax3.set_axisbelow(True)
ax3.yaxis.grid(True, linestyle='--', alpha=0.3)
ax3.tick_params(axis='y', labelsize=11)

# Section divider between Sample/Weighting and Model Fit
ax3.axvline(x=3.5, color='#CCCCCC', linewidth=1.5, linestyle='-', alpha=0.6)
ax3.text(1.5, 5.5, 'Sample & Weighting', ha='center', fontsize=11, fontweight='bold', 
         color=COLORS['primary'], bbox=dict(boxstyle='round,pad=0.3', 
         facecolor='white', edgecolor=COLORS['border'], alpha=0.9))
ax3.text(7, 5.5, 'Model Fit', ha='center', fontsize=11, fontweight='bold', 
         color=COLORS['primary'], bbox=dict(boxstyle='round,pad=0.3', 
         facecolor='white', edgecolor=COLORS['border'], alpha=0.9))

plt.tight_layout()
fig3.subplots_adjust(bottom=0.16, top=0.88)

fig3.savefig(out_dir / "standards_sample_modelfit.png", dpi=300, bbox_inches='tight',
             facecolor='white', edgecolor='none')
print(f"Saved: {out_dir / 'standards_sample_modelfit.png'}")
plt.close()

# --------------------------------------------------------------------------
# CHART 2: Specification, Bootstrap & Effect Reporting (10 metrics)
# --------------------------------------------------------------------------
metrics_chart2 = [
    # Specification (2)
    ('Interaction', 'X×Z product', 1.0, 'Product term'),
    ('Identifiability', 'df = 546', 1.0, 'df > 0'),
    # Bootstrap (4)
    ('Boot Design', 'BTW', 1.0, 'Nonparametric'),
    ('CI Method', 'BCa', 1.0, 'BCa/Percentile'),
    ('Bootstrap B', f'B={ACTUAL_DATA["bootstrap_b"]}', ACTUAL_DATA["bootstrap_b"] / 1000, '≥1,000'),
    ('Convergence', f'{ACTUAL_DATA["bootstrap_pct"]:.0f}%', ACTUAL_DATA["bootstrap_pct"] / 95, '≥95%'),
    # Effects (4)
    ('Direct Eff.', 'Est + BCa CI', 1.0, 'Est + CI'),
    ('Indirect Eff.', 'BCa CI', 1.0, 'Bootstrap CI'),
    ('Cond. Indirect', '±1 SD', 1.0, 'Low/Mid/High'),
    ('IMM', 'BCa CI', 1.0, 'Point + CI'),
]

fig4, ax4 = plt.subplots(figsize=(16, 9))
fig4.patch.set_facecolor('white')
ax4.set_facecolor('white')

categories2 = [m[0] for m in metrics_chart2]
actual_values2 = [m[1] for m in metrics_chart2]
ratios2 = [m[2] for m in metrics_chart2]
benchmarks2 = [m[3] for m in metrics_chart2]

x_pos2 = np.arange(len(categories2))

bars2 = ax4.bar(x_pos2, ratios2, width=bar_width, color='#1A1A1A', 
                edgecolor='white', linewidth=0.5, alpha=0.9)

for bar, ratio in zip(bars2, ratios2):
    if ratio >= 1.0:
        bar.set_facecolor('#1A1A1A')
    else:
        bar.set_facecolor('#FB8C00')

ax4.axhline(y=1.0, color='#C62828', linewidth=2.5, linestyle='--', alpha=0.8)

for i, (bar, actual_val) in enumerate(zip(bars2, actual_values2)):
    height = bar.get_height()
    display_height = min(height, 2.0)
    ax4.text(bar.get_x() + bar.get_width()/2, display_height + 0.08, 
             actual_val, ha='center', fontsize=11, color='#1A1A1A', 
             fontweight='bold', rotation=0)

for i, (x, bench) in enumerate(zip(x_pos2, benchmarks2)):
    ax4.text(x, -0.22, f'[{bench}]', ha='center', fontsize=9, 
             color=COLORS['subtext'], style='italic')

ax4.set_xticks(x_pos2)
ax4.set_xticklabels(categories2, fontsize=11, ha='center')
ax4.set_ylabel('Ratio to Benchmark', fontsize=14, fontweight='bold')
ax4.set_ylim(-0.55, 2.5)

# Title using suptitle for proper spacing
fig4.suptitle('Specification, Bootstrap & Effect Reporting Standards', 
              fontsize=22, fontweight='bold', color='#1A1A1A', y=0.98)
ax4.set_title('Developmental Adjustment among Accelerated Dual Credit Students | Conditional Process SEM Validation Study\n'
              'Results From an Empirically Informed Simulated Dataset Based on Current Reports on CSU Populations',
              fontsize=11, style='italic', color='#444444', pad=18, linespacing=1.3)

# Note at bottom
fig4.text(0.5, 0.02, 
          'Note: Each criterion is assessed independently against its own field-specific benchmark. '
          'Bar height represents ratio of observed value to threshold (ratio ≥ 1.0 = benchmark met). '
          'Labels display actual observed values.',
          ha='center', fontsize=9, color='#666666', style='italic', wrap=True)

# Legend removed per user request

ax4.spines['top'].set_visible(False)
ax4.spines['right'].set_visible(False)
ax4.set_axisbelow(True)
ax4.yaxis.grid(True, linestyle='--', alpha=0.3)
ax4.tick_params(axis='y', labelsize=11)

# Section dividers
ax4.axvline(x=1.5, color='#CCCCCC', linewidth=1.5, linestyle='-', alpha=0.6)
ax4.axvline(x=5.5, color='#CCCCCC', linewidth=1.5, linestyle='-', alpha=0.6)
ax4.text(0.5, 2.35, 'Specification', ha='center', fontsize=11, fontweight='bold', 
         color=COLORS['primary'], bbox=dict(boxstyle='round,pad=0.3', 
         facecolor='white', edgecolor=COLORS['border'], alpha=0.9))
ax4.text(3.5, 2.35, 'Bootstrap', ha='center', fontsize=11, fontweight='bold', 
         color=COLORS['primary'], bbox=dict(boxstyle='round,pad=0.3', 
         facecolor='white', edgecolor=COLORS['border'], alpha=0.9))
ax4.text(7.5, 2.35, 'Effect Reporting', ha='center', fontsize=11, fontweight='bold', 
         color=COLORS['primary'], bbox=dict(boxstyle='round,pad=0.3', 
         facecolor='white', edgecolor=COLORS['border'], alpha=0.9))

plt.tight_layout()
fig4.subplots_adjust(bottom=0.16, top=0.88)

fig4.savefig(out_dir / "standards_bootstrap_effects.png", dpi=300, bbox_inches='tight',
             facecolor='white', edgecolor='none')
print(f"Saved: {out_dir / 'standards_bootstrap_effects.png'}")
plt.close()

print("\n✅ Professional standards visualizations complete!")
